{
 "cells": [
  {
   "cell_type": "raw",
   "id": "57db5b9d-fc97-4ca9-bb64-16e6d33b8b8a",
   "metadata": {},
   "source": [
    "## Create a custom training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20368357-e9a2-4930-9d81-8d4b2619a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary packages\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "#Import keras, sklearn, tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "#import other common packages\n",
    "import numpy as np\n",
    "import os\n",
    "#!pip install tqdm ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab312072-615b-4a70-a9c6-a68b445e7605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the training data to further training and validation set\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255.\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test.astype(np.float32) / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f272bab-ce65-41da-851d-e20e173fc29f",
   "metadata": {},
   "source": [
    "## Create the custom loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e1d4af-d357-4e83-a154-05f42af828f0",
   "metadata": {},
   "source": [
    "#### Start by creating a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f114a91-f2e6-40fe-9134-ea49e3e2d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation = \"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c94ee-6ce4-4874-bb21-deea4a131539",
   "metadata": {},
   "source": [
    "### Create a function that randomly selects a batch from the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "534010ca-2a30-4dc1-a7e6-f5320b7394c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size= batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db75f7c-3542-4e90-824d-5c2f5786340a",
   "metadata": {},
   "source": [
    "### Define a function that will display the training status, including number of steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343ac301-3228-4f11-9e34-4aa5f56eb70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result()) for m in [loss] + (metrics or [])])\n",
    "    end =  \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration, total) + metrics, end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2f5b2-088d-44ca-b9f2-f99c665b7e9e",
   "metadata": {},
   "source": [
    "### Now let's create the custom looping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f23854-ce5c-45ad-b557-b510f79650c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start by defining some hyperparameters\n",
    "n_epochs = 5\n",
    "batch_size=32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "\n",
    "#import trange\n",
    "from tqdm.notebook import trange\n",
    "from collections import OrderedDict\n",
    "\n",
    "#create the loop\n",
    "try:\n",
    "    with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "        for epoch in epochs:\n",
    "            with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epochs, n_epochs)) as steps:\n",
    "                for step in steps:\n",
    "                    X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        y_pred = model(X_batch)\n",
    "                        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                        loss = tf.add_n([main_loss] + model.losses)\n",
    "                        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                        for variable in model.variables:\n",
    "                            if variable.constraint is not None:\n",
    "                                variable.assign(variable.constraint(variable))\n",
    "                        status = OrderedDict()\n",
    "                        mean_loss(loss)\n",
    "                        status[\"loss\"] = mean_loss.result().numpy()\n",
    "                        for metric in metrics:                   \n",
    "                            metric(y_batch, y_pred)\n",
    "                            status[metric.name] =  metric.result().numpy()\n",
    "                            steps.set_postfix(status)\n",
    "                    y_pred = model(X_valid)\n",
    "                    status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "                    status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "                    steps.set_postfix(status)\n",
    "                    for metric in [mean_loss] + metrics:\n",
    "                        metric.reset_states()\n",
    "except ImportError as ex:\n",
    "    print(\"To run this cell, please install tqdm, ipywidgets and restart Jupyter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c13f3-b8c4-4647-8198-89cd2e034678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_networks",
   "language": "python",
   "name": "neural_networks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
